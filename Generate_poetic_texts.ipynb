{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nandiniiy/Poetic-Texts-Project/blob/main/Generate_poetic_texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai_MBHjMEhHJ"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "DbWwlsmjExYI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy3L2SlgExbt",
        "outputId": "7663f460-06c9-48c1-ef4c-7169f5330c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters)), kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "model.add(Dropout(0.2)) # Add dropout after the LSTM layer\n",
        "model.add(Dense(len(characters)))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4jrmqrSOauv",
        "outputId": "9bb27644-a75c-4721-a80d-435729492ee0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t_PQwY1ExfV"
      },
      "outputs": [],
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding = 'utf-8').lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)  # Adjust patience as needed\n",
        "\n",
        "model.fit(x, y, batch_size=256, epochs=10, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZbjZqGCV48b",
        "outputId": "d638c0d8-f7f5-4746-92e3-3664fd4631f2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 191ms/step - loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 184ms/step - loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 187ms/step - loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 185ms/step - loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 183ms/step - loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 186ms/step - loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 183ms/step - loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 192ms/step - loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 189ms/step - loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 185ms/step - loss: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dbd44329900>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD_r4MRGExiv"
      },
      "outputs": [],
      "source": [
        "text = text[300000:800000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXhryzQ5GPzy"
      },
      "outputs": [],
      "source": [
        "characters = sorted(set(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEX9DMDlGP3N"
      },
      "outputs": [],
      "source": [
        "char_to_index = dict((c, i) for i, c in enumerate(characters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBQDSz5iGP7G"
      },
      "outputs": [],
      "source": [
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrPzx0GiGQEy"
      },
      "outputs": [],
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXe0rzqPGP-e"
      },
      "outputs": [],
      "source": [
        "sentences= []\n",
        "next_characters = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Bp1cyWGQJZ"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH , STEP_SIZE):\n",
        "  sentences.append(text [i: i+SEQ_LENGTH])\n",
        "  next_characters.append(text[i+SEQ_LENGTH])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "artQyUWZOhhf"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BabT7uVSPfyd"
      },
      "outputs": [],
      "source": [
        "y = np.zeros((len(sentences), len(characters)), dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlXCVyn9NaOx"
      },
      "outputs": [],
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "  for t, character in enumerate(sentence):\n",
        "    x[i, t, char_to_index[character]] = 1\n",
        "  y[i, char_to_index[next_characters[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MUa4C2oNaR3"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlh_KphcYfIE",
        "outputId": "7f301d73-4742-4584-fe4f-397f2324f7c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5GjN67MY33Y"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(len(characters)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfOjphu4ZAd4"
      },
      "outputs": [],
      "source": [
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72G2xiKaNaVQ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ9zkv_eNaYp",
        "outputId": "1d20f48f-8b0f-4a3b-d25d-647c2400fbc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 184ms/step - loss: 1.1744e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 181ms/step - loss: 1.7918e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 183ms/step - loss: 7.9043e-06\n",
            "Epoch 4/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 181ms/step - loss: 4.1738e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 188ms/step - loss: 1.1085e-07\n",
            "Epoch 6/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 186ms/step - loss: 5.1405e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 188ms/step - loss: 4.8108e-07\n",
            "Epoch 8/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 179ms/step - loss: 1.0364e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 183ms/step - loss: 3.7080e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 190ms/step - loss: 4.5928e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dbd46b0c910>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "model.fit(x,y, batch_size=256, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkt5pSbyeuBl"
      },
      "outputs": [],
      "source": [
        "model.save('textgenerator.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_ABUV93e4fH"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('textgenerator.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "4cQp98-5n_pl"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds + 1e-10) / temperature  # Add a small epsilon here\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mpZBemL8ntw5"
      },
      "outputs": [],
      "source": [
        "def generate_text(length, temperature):\n",
        "  start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "  generated = ''\n",
        "  sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "  generated += sentence\n",
        "  for i in range(length):\n",
        "    x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "    for t, character in enumerate(sentence):\n",
        "      x[0, t, char_to_index[character]] = 1\n",
        "    predictions = model.predict(x, verbose=0)[0]\n",
        "    predictions = np.clip(predictions, 1e-10, 1 - 1e-10)  # Clip values to a safe range\n",
        "    next_index = sample(predictions, temperature)  # Use the modified sample function\n",
        "    next_character = index_to_char[next_index]\n",
        "    generated += next_character\n",
        "    sentence = sentence[1:] + next_character # This line was indented incorrectly, causing the issue.\n",
        "  return generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phL1N5-ag7DF"
      },
      "outputs": [],
      "source": [
        "print(\"-------0.2------\")\n",
        "print(generate_text(300, 0.2))\n",
        "print(\"-------0.4------\")\n",
        "print(generate_text(300, 0.4))\n",
        "print(\"-------0.6------\")\n",
        "print(generate_text(300, 0.6))\n",
        "print(\"-------0.8------\")\n",
        "print(generate_text(300, 0.8))\n",
        "print(\"-------1.0------\")\n",
        "print(generate_text(300, 1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewcKGvjMg7F-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGmjZktdg7JD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFv4TcywdRx1s8XwZs8lFL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}